{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import jieba\n",
    "import sys\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.2 (v3.8.2:7b3ab5921f, Feb 24 2020, 17:52:18) \n",
      "[Clang 6.0 (clang-600.0.57)]\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2idx(embedding):\n",
    "    wordidx = {}\n",
    "    for i in range(len(embedding)):\n",
    "        wordidx[embedding['name'][i]] = i\n",
    "    return(wordidx)\n",
    "    \n",
    "def sen2idx(sen, wordidx):\n",
    "    idxword = []\n",
    "    for s in sen:\n",
    "        try:\n",
    "            idx = wordidx[s]\n",
    "            idxword.append(idx)\n",
    "        except:\n",
    "            continue\n",
    "    return(idxword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'Replication_TrainingDatasetCensorship/') # set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/8g/74cy_pd90b94x2b6lxyf92v40000gn/T/jieba.cache\n",
      "Loading model cost 0.692 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "jieba.load_userdict(\"auxiliary/Dict.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words =[# freedom\n",
    "    \"自由\", \"言论自由\", \"集会自由\", \"新闻自由\", \"结社自由\", \"自由权\", \"民主自由\", \"自由言论\", \"创作自由\", \n",
    "    \"婚姻自主\", \"自由民主\", \"自由市场\", \"自决\", \"自决权\", \"生而自由\", \"自由自在\", \"自由选择\", \"自由思想\", \n",
    "    \"公民自由\", \"自由竞争\", \"宗教自由\", \"自由价格\", \n",
    "    # democracy\n",
    "    \"民主\", \"自由民主\", \"民主自由\", \"民主制度\", \"民主化\", \"社会民主主义\", \"民主运动\", \"民主主义\", \"民主改革\", \n",
    "    \"民主制\", \"民主选举\", \"民主权力\", \"多党制\", \"民主法制\", \"民主权利\" ,\n",
    "    # election\n",
    "    \"选举\", \"直接选举\", \"议会选举\", \"间接选举\", \"直选\", \"换届选举\", \"民选\", \"投票选举\", \"全民公决\", \"总统大选\", \n",
    "    \"大选\", \"普选\", \"全民投票\", \"民主选举\",\n",
    "    # collective action\n",
    "    \"抗议\", \"示威\", \"示威游行\", \"示威抗议\", \"游行示威\", \"静坐示威\", \"绝食抗议\", \"请愿\", \"示威运动\", \"游行\", \n",
    "    \"罢教\", \"静坐\", \"集会游行\", \"罢课\", \"签名运动\", \n",
    "    # negative figures\n",
    "    \"林彪\", \"王洪文\", \"张春桥\", \"江青\", \"姚文元\", \"刘晓波\", \"丹增嘉措\", \"李洪志\", \"陈水扁\", \"黎智英\", \"艾未未\", \n",
    "    \"李登辉\", \"李柱铭\", \"何俊仁\", \"陈方安生\", \"达赖\", \"魏京生\",\n",
    "    # social control\n",
    "    \"维稳\", \"处突\", \"社会治安\", \"反恐怖\", \"公安工作\", \"预防犯罪\", \"收容审查\", \"治安工作\", \"大排查\", \"扫黄打非\", \n",
    "    \"接访\", \"反邪教\",\n",
    "    # surveillance\n",
    "    \"监控\", \"监测\", \"监视\", \"管控\", \"监看\", \"监视系统\", \"截听\", \"监控中心\", \"情报服务\", \"排查\", \"监视器\",\n",
    "    \"情报搜集\", \"间谍卫星\", \"管理网络\", \"监控器\", \"监控站\", \"监控室\", \"数据采集\", \n",
    "    # CCP\n",
    "    \"党中央\",  \"中国共产党\", \"党支部\", \"中共中央\", \"共青团\", \"共青团中央\", \"党委\", \"中央党校\",\n",
    "    # historical events\n",
    "    \"抗日战争\", \"解放战争\", \"抗美援朝\", \"改革开放\", \"香港回归\", \"长征\", \"三大战役\", \"秋收起义\", \"南昌起义\", \"志愿军\", \n",
    "    \"土地改革\", \"六四\", \"遵义会议\", \"广州起义\", \"百团大战\", \"文革\", \"文化大革命\", \"大跃进\", \"四人帮\",\n",
    "    # positive figures\n",
    "    \"毛泽东\", \"江泽民\", \"胡锦涛\", \"习近平\", \"周恩来\", \"朱镕基\", \"温家宝\", \"李克强\", \"邓小平\", \"曾庆红\", \"华国锋\", \"李鹏\", \n",
    "    \"杨尚昆\", \"谷牧\", \"吴邦国\", \"李岚清\", \"纪登奎\", \"乔石\",\"邹家华\", \"李瑞环\", \"俞正声\", \"张高丽\", \"田纪云\", \"回良玉\", \n",
    "    \"李源潮\", \"贾庆林\", \"姚依林\", \"张立昌\", \"尉健行\", \"姜春云\", \"李铁映\", \"王兆国\", \"罗干\", \"杨汝岱\", \"王光英\", \"彭佩云\", \n",
    "    \"刘云山\", \"丁关根\", \"彭真\", \"胡启立\", \"曾培炎\", \"何东昌\"]\n",
    "\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baidubaike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>达里奥资本市场已不再自由贫富差距达年代以来最严重</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>新闻自由日联合国秘书长强调记者为新冠大流行错误信息提供</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>一组老照片自由女神像是如何诞生的</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>在互联网自由日抗议苹果公司同中共合作审查网络</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>香港居民权利自由的坚实保障</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sentence  label\n",
       "0     达里奥资本市场已不再自由贫富差距达年代以来最严重     -1\n",
       "1  新闻自由日联合国秘书长强调记者为新冠大流行错误信息提供     -1\n",
       "2             一组老照片自由女神像是如何诞生的      1\n",
       "3       在互联网自由日抗议苹果公司同中共合作审查网络     -1\n",
       "4                香港居民权利自由的坚实保障      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove punctuation, news agencies, duplicate headlines, numbers & English letters\n",
    "# test set\n",
    "news = pd.read_csv('auxiliary/Political_news_titles.csv')\n",
    "news = news[news['label'].isnull()==False]\n",
    "punct = ['......', '，', '--', '：',  '丨', '「', '」', '、', '——',  '-',  '_', '...', '·', '。',\n",
    "        '【', '】', '《', '》', '/', '(图)', '(组图)', '[图]', '‧', '.', ':', ',', '（下）', '（上）', '（图）', '（组图）', ' ',\n",
    "        '丨', '|', '(', ')', '（', '）', '[', ']', \"'\", '’', '‘', '“', '”', '%', '?', '!']\n",
    "for i in range(len(news)):\n",
    "    text = news.iloc[i,0]\n",
    "    for p in punct:\n",
    "      text = text.replace(p, \"\")\n",
    "    text = re.sub('[a-zA-Z]','',text)\n",
    "    text = re.sub(\"\\d+\", \"\", text)\n",
    "    news.iloc[i,0] = text\n",
    "news = news[news['label']!=0]\n",
    "news.drop_duplicates(subset=['sentence'], inplace=True)\n",
    "news = news.dropna(how='any',axis=0) \n",
    "news = news.reset_index(drop=True)\n",
    "news[\"label\"] = news[\"label\"].astype(int)\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2420"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training set\n",
    "train = pd.read_csv('auxiliary/TNEWS_subset.csv')\n",
    "train = train[train['label'].isnull()==False]\n",
    "for i in range(len(train)):\n",
    "    text = train.iloc[i,0]\n",
    "    for p in punct:\n",
    "      text = text.replace(p, \"\")\n",
    "    text = re.sub('[a-zA-Z]','',text)\n",
    "    text = re.sub(\"\\d+\", \"\", text)\n",
    "    train.iloc[i,0] = text\n",
    "train = train[train['label']!=0]\n",
    "train.drop_duplicates(subset=['sentence'], inplace=True)\n",
    "train = train.dropna(how='any',axis=0) \n",
    "train = train.reset_index(drop=True)\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V292</th>\n",
       "      <th>V293</th>\n",
       "      <th>V294</th>\n",
       "      <th>V295</th>\n",
       "      <th>V296</th>\n",
       "      <th>V297</th>\n",
       "      <th>V298</th>\n",
       "      <th>V299</th>\n",
       "      <th>V300</th>\n",
       "      <th>V301</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>，</td>\n",
       "      <td>-0.242002</td>\n",
       "      <td>0.139317</td>\n",
       "      <td>0.073788</td>\n",
       "      <td>-0.191109</td>\n",
       "      <td>0.088181</td>\n",
       "      <td>0.130866</td>\n",
       "      <td>0.126029</td>\n",
       "      <td>-0.072774</td>\n",
       "      <td>0.033516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011133</td>\n",
       "      <td>0.172242</td>\n",
       "      <td>0.198639</td>\n",
       "      <td>0.049223</td>\n",
       "      <td>-0.054923</td>\n",
       "      <td>-0.083077</td>\n",
       "      <td>-0.085516</td>\n",
       "      <td>0.141039</td>\n",
       "      <td>0.055923</td>\n",
       "      <td>-0.080048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>的</td>\n",
       "      <td>-0.086717</td>\n",
       "      <td>0.077708</td>\n",
       "      <td>0.095153</td>\n",
       "      <td>-0.077534</td>\n",
       "      <td>-0.201572</td>\n",
       "      <td>-0.039050</td>\n",
       "      <td>0.224178</td>\n",
       "      <td>-0.177118</td>\n",
       "      <td>-0.027403</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>0.170862</td>\n",
       "      <td>0.145751</td>\n",
       "      <td>0.109331</td>\n",
       "      <td>0.044553</td>\n",
       "      <td>0.032508</td>\n",
       "      <td>-0.257849</td>\n",
       "      <td>0.111964</td>\n",
       "      <td>0.030822</td>\n",
       "      <td>-0.128930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>。</td>\n",
       "      <td>-0.114365</td>\n",
       "      <td>0.122019</td>\n",
       "      <td>0.028330</td>\n",
       "      <td>-0.154405</td>\n",
       "      <td>-0.082406</td>\n",
       "      <td>0.006950</td>\n",
       "      <td>0.244836</td>\n",
       "      <td>-0.022653</td>\n",
       "      <td>0.054961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150479</td>\n",
       "      <td>0.037960</td>\n",
       "      <td>0.077362</td>\n",
       "      <td>0.077516</td>\n",
       "      <td>0.042213</td>\n",
       "      <td>0.055036</td>\n",
       "      <td>0.039008</td>\n",
       "      <td>0.110687</td>\n",
       "      <td>0.036073</td>\n",
       "      <td>-0.137635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>、</td>\n",
       "      <td>-0.218755</td>\n",
       "      <td>0.104672</td>\n",
       "      <td>-0.032240</td>\n",
       "      <td>-0.175267</td>\n",
       "      <td>-0.031778</td>\n",
       "      <td>0.085487</td>\n",
       "      <td>0.042656</td>\n",
       "      <td>-0.130028</td>\n",
       "      <td>0.323578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092067</td>\n",
       "      <td>0.191939</td>\n",
       "      <td>-0.080064</td>\n",
       "      <td>-0.140970</td>\n",
       "      <td>-0.223796</td>\n",
       "      <td>0.046355</td>\n",
       "      <td>-0.174176</td>\n",
       "      <td>-0.062020</td>\n",
       "      <td>-0.004782</td>\n",
       "      <td>0.213918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,</td>\n",
       "      <td>-0.166416</td>\n",
       "      <td>0.458875</td>\n",
       "      <td>0.117787</td>\n",
       "      <td>-0.300892</td>\n",
       "      <td>-0.232379</td>\n",
       "      <td>0.109313</td>\n",
       "      <td>-0.325269</td>\n",
       "      <td>-0.166099</td>\n",
       "      <td>-0.742212</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099326</td>\n",
       "      <td>0.021598</td>\n",
       "      <td>-0.142140</td>\n",
       "      <td>0.352612</td>\n",
       "      <td>-0.080029</td>\n",
       "      <td>0.281831</td>\n",
       "      <td>-0.281419</td>\n",
       "      <td>0.442771</td>\n",
       "      <td>0.091643</td>\n",
       "      <td>-0.376297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  name        V2        V3        V4        V5        V6        V7        V8  \\\n",
       "0    ， -0.242002  0.139317  0.073788 -0.191109  0.088181  0.130866  0.126029   \n",
       "1    的 -0.086717  0.077708  0.095153 -0.077534 -0.201572 -0.039050  0.224178   \n",
       "2    。 -0.114365  0.122019  0.028330 -0.154405 -0.082406  0.006950  0.244836   \n",
       "3    、 -0.218755  0.104672 -0.032240 -0.175267 -0.031778  0.085487  0.042656   \n",
       "4    , -0.166416  0.458875  0.117787 -0.300892 -0.232379  0.109313 -0.325269   \n",
       "\n",
       "         V9       V10  ...      V292      V293      V294      V295      V296  \\\n",
       "0 -0.072774  0.033516  ...  0.011133  0.172242  0.198639  0.049223 -0.054923   \n",
       "1 -0.177118 -0.027403  ... -0.000238  0.170862  0.145751  0.109331  0.044553   \n",
       "2 -0.022653  0.054961  ...  0.150479  0.037960  0.077362  0.077516  0.042213   \n",
       "3 -0.130028  0.323578  ...  0.092067  0.191939 -0.080064 -0.140970 -0.223796   \n",
       "4 -0.166099 -0.742212  ... -0.099326  0.021598 -0.142140  0.352612 -0.080029   \n",
       "\n",
       "       V297      V298      V299      V300      V301  \n",
       "0 -0.083077 -0.085516  0.141039  0.055923 -0.080048  \n",
       "1  0.032508 -0.257849  0.111964  0.030822 -0.128930  \n",
       "2  0.055036  0.039008  0.110687  0.036073 -0.137635  \n",
       "3  0.046355 -0.174176 -0.062020 -0.004782  0.213918  \n",
       "4  0.281831 -0.281419  0.442771  0.091643 -0.376297  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load Baidubaike word embedding\n",
    "bd = pd.read_csv('output/2.dropna_baidubaike_clean.csv')\n",
    "bd.rename(columns={'Unnamed: 0': 'name'}, inplace=True)\n",
    "bd_wordidx = word2idx(bd)\n",
    "bd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "2500\n",
      "5000\n",
      "7500\n"
     ]
    }
   ],
   "source": [
    "train_embedding = pd.DataFrame(index=range(0, len(train)), columns=range(0, 300))\n",
    "test_embedding = pd.DataFrame(index=range(0, len(news)), columns=range(0, 300))\n",
    "\n",
    "# convert headlines in training set to word embedding\n",
    "for i in range(0, len(train)):\n",
    "    text = jieba.lcut(train.iloc[i,0])\n",
    "    textidx = sen2idx(text, bd_wordidx)\n",
    "    train_embedding.loc[i] = bd.loc[textidx,'V2':'V301'].mean(axis=0).values\n",
    "    if i%1000==0:\n",
    "        print(i)\n",
    "        \n",
    "# convert headlines in test set to word embedding\n",
    "for i in range(0, len(news)):\n",
    "    text = jieba.lcut(news.iloc[i,0])\n",
    "    textidx = sen2idx(text, bd_wordidx)\n",
    "    test_embedding.loc[i] = bd.loc[textidx,'V2':'V301'].mean(axis=0).values\n",
    "    if i%2500==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lab = train['label'][train_embedding.isnull().any(axis=1)==False].values\n",
    "train_embedding = train_embedding.loc[train_embedding.isnull().any(axis=1)==False]\n",
    "test_lab = news['label'][test_embedding.isnull().any(axis=1)==False].values\n",
    "news = news.loc[test_embedding.isnull().any(axis=1)==False]\n",
    "test_embedding = test_embedding.loc[test_embedding.isnull().any(axis=1)==False]\n",
    "train_bd = preprocessing.scale(train_embedding)\n",
    "test_bd = preprocessing.scale(test_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7759322406775933\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(train_bd,train_lab)\n",
    "y_pred=clf.predict(test_bd)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_lab, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(news)):\n",
    "    news.iloc[i, 0] = ' ' + ' '.join(jieba.lcut(news.iloc[i, 0]))+' '\n",
    "\n",
    "# store prediction\n",
    "res = pd.DataFrame(index=range(5000), columns=range(20))\n",
    "category = [range(0, 22), range(22, 37), range(37, 51), range(51, 66), range(66,83), \n",
    "            range(83, 95), range(95, 113), range(113, 121), range(121, 140), range(140, 182)]\n",
    "for n, c in enumerate(category):\n",
    "    counter = 0\n",
    "    for w in c:\n",
    "        counter += 1\n",
    "        word = ' ' + words[w] + ' '\n",
    "        id = [i for i in range(len(news)) if word in news.iloc[i, 0]]\n",
    "        dif = (y_pred[id] - test_lab[id])\n",
    "        start = 5000 - res.iloc[:,n].isnull().sum()\n",
    "        end = start + len(dif.tolist())\n",
    "        res.iloc[start:end, n] = dif.tolist()\n",
    "        res.iloc[start:end, n+10] = counter\n",
    "res.to_csv(r'output/svm_bd.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7688923110768893\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(train_bd,train_lab)\n",
    "y_pred=clf.predict(test_bd)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_lab, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(index=range(5000), columns=range(20))\n",
    "category = [range(0, 22), range(22, 37), range(37, 51), range(51, 66), range(66,83), \n",
    "            range(83, 95), range(95, 113), range(113, 121), range(121, 140), range(140, 182)]\n",
    "for n, c in enumerate(category):\n",
    "    counter = 0\n",
    "    for w in c:\n",
    "        counter += 1\n",
    "        word = ' ' + words[w] + ' '\n",
    "        id = [i for i in range(len(news)) if word in news.iloc[i, 0]]\n",
    "        dif = (y_pred[id] - test_lab[id])\n",
    "        start = 5000 - res.iloc[:,n].isnull().sum()\n",
    "        end = start + len(dif.tolist())\n",
    "        res.iloc[start:end, n] = dif.tolist()\n",
    "        res.iloc[start:end, n+10] = counter\n",
    "res.to_csv(r'output/nb_bd.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>达里奥资本市场已不再自由贫富差距达年代以来最严重</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>新闻自由日联合国秘书长强调记者为新冠大流行错误信息提供</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>一组老照片自由女神像是如何诞生的</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>在互联网自由日抗议苹果公司同中共合作审查网络</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>香港居民权利自由的坚实保障</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sentence  label\n",
       "0     达里奥资本市场已不再自由贫富差距达年代以来最严重     -1\n",
       "1  新闻自由日联合国秘书长强调记者为新冠大流行错误信息提供     -1\n",
       "2             一组老照片自由女神像是如何诞生的      1\n",
       "3       在互联网自由日抗议苹果公司同中共合作审查网络     -1\n",
       "4                香港居民权利自由的坚实保障      1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv('auxiliary/Political_news_titles.csv')\n",
    "news = news[news['label'].isnull()==False]\n",
    "punct = ['......', '，', '--', '：',  '丨', '「', '」', '、', '——',  '-',  '_', '...', '·', '。',\n",
    "        '【', '】', '《', '》', '/', '(图)', '(组图)', '[图]', '‧', '.', ':', ',', '（下）', '（上）', '（图）', '（组图）', ' ',\n",
    "        '丨', '|', '(', ')', '（', '）', '[', ']', \"'\", '’', '‘', '“', '”', '%', '?', '!']\n",
    "for i in range(len(news)):\n",
    "    text = news.iloc[i,0]\n",
    "    for p in punct:\n",
    "      text = text.replace(p, \"\")\n",
    "    text = re.sub('[a-zA-Z]','',text)\n",
    "    text = re.sub(\"\\d+\", \"\", text)\n",
    "    news.iloc[i,0] = text\n",
    "news = news[news['label']!=0]\n",
    "news.drop_duplicates(subset=['sentence'], inplace=True)\n",
    "news = news.dropna(how='any',axis=0) \n",
    "news = news.reset_index(drop=True)\n",
    "news[\"label\"] = news[\"label\"].astype(int)\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2420"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('auxiliary/TNEWS_subset.csv')\n",
    "train = train[train['label'].isnull()==False]\n",
    "for i in range(len(train)):\n",
    "    text = train.iloc[i,0]\n",
    "    for p in punct:\n",
    "      text = text.replace(p, \"\")\n",
    "    text = re.sub('[a-zA-Z]','',text)\n",
    "    text = re.sub(\"\\d+\", \"\", text)\n",
    "    train.iloc[i,0] = text\n",
    "train = train[train['label']!=0]\n",
    "train.drop_duplicates(subset=['sentence'], inplace=True)\n",
    "train = train.dropna(how='any',axis=0) \n",
    "train = train.reset_index(drop=True)\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V292</th>\n",
       "      <th>V293</th>\n",
       "      <th>V294</th>\n",
       "      <th>V295</th>\n",
       "      <th>V296</th>\n",
       "      <th>V297</th>\n",
       "      <th>V298</th>\n",
       "      <th>V299</th>\n",
       "      <th>V300</th>\n",
       "      <th>V301</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>，</td>\n",
       "      <td>0.150785</td>\n",
       "      <td>0.120591</td>\n",
       "      <td>-0.220204</td>\n",
       "      <td>-0.044533</td>\n",
       "      <td>0.374161</td>\n",
       "      <td>0.044214</td>\n",
       "      <td>-0.392151</td>\n",
       "      <td>0.035214</td>\n",
       "      <td>0.300220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187215</td>\n",
       "      <td>-0.150791</td>\n",
       "      <td>0.339811</td>\n",
       "      <td>0.069382</td>\n",
       "      <td>-0.323648</td>\n",
       "      <td>0.108729</td>\n",
       "      <td>0.065358</td>\n",
       "      <td>-0.532687</td>\n",
       "      <td>-0.066914</td>\n",
       "      <td>-0.100728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>的</td>\n",
       "      <td>-0.251355</td>\n",
       "      <td>0.234742</td>\n",
       "      <td>-0.169728</td>\n",
       "      <td>0.026955</td>\n",
       "      <td>0.258850</td>\n",
       "      <td>0.028063</td>\n",
       "      <td>-0.498176</td>\n",
       "      <td>0.076507</td>\n",
       "      <td>0.151926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206175</td>\n",
       "      <td>-0.320072</td>\n",
       "      <td>0.206702</td>\n",
       "      <td>0.297621</td>\n",
       "      <td>-0.255238</td>\n",
       "      <td>0.076537</td>\n",
       "      <td>-0.021104</td>\n",
       "      <td>-0.527221</td>\n",
       "      <td>-0.229531</td>\n",
       "      <td>0.180781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>。</td>\n",
       "      <td>0.207820</td>\n",
       "      <td>0.141425</td>\n",
       "      <td>-0.337281</td>\n",
       "      <td>0.158955</td>\n",
       "      <td>0.232709</td>\n",
       "      <td>0.008633</td>\n",
       "      <td>-0.401047</td>\n",
       "      <td>-0.088699</td>\n",
       "      <td>0.113330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108845</td>\n",
       "      <td>-0.074981</td>\n",
       "      <td>0.104715</td>\n",
       "      <td>-0.035879</td>\n",
       "      <td>-0.365303</td>\n",
       "      <td>-0.142196</td>\n",
       "      <td>0.015788</td>\n",
       "      <td>-0.555588</td>\n",
       "      <td>0.047561</td>\n",
       "      <td>-0.070897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>、</td>\n",
       "      <td>0.020587</td>\n",
       "      <td>-0.472420</td>\n",
       "      <td>-0.441270</td>\n",
       "      <td>0.650659</td>\n",
       "      <td>0.406180</td>\n",
       "      <td>-0.197017</td>\n",
       "      <td>-0.230998</td>\n",
       "      <td>-0.362920</td>\n",
       "      <td>-0.372085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111319</td>\n",
       "      <td>-0.080049</td>\n",
       "      <td>0.768271</td>\n",
       "      <td>0.100696</td>\n",
       "      <td>-0.348324</td>\n",
       "      <td>-0.236327</td>\n",
       "      <td>0.031901</td>\n",
       "      <td>-0.870347</td>\n",
       "      <td>0.510523</td>\n",
       "      <td>0.065956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>和</td>\n",
       "      <td>0.009246</td>\n",
       "      <td>0.187802</td>\n",
       "      <td>0.066590</td>\n",
       "      <td>-0.095002</td>\n",
       "      <td>0.193442</td>\n",
       "      <td>0.067781</td>\n",
       "      <td>-0.194179</td>\n",
       "      <td>-0.203283</td>\n",
       "      <td>-0.278398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300195</td>\n",
       "      <td>-0.004085</td>\n",
       "      <td>0.388441</td>\n",
       "      <td>-0.042360</td>\n",
       "      <td>-0.064346</td>\n",
       "      <td>-0.161472</td>\n",
       "      <td>0.136743</td>\n",
       "      <td>-0.496433</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.038096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  name        V2        V3        V4        V5        V6        V7        V8  \\\n",
       "0    ，  0.150785  0.120591 -0.220204 -0.044533  0.374161  0.044214 -0.392151   \n",
       "1    的 -0.251355  0.234742 -0.169728  0.026955  0.258850  0.028063 -0.498176   \n",
       "2    。  0.207820  0.141425 -0.337281  0.158955  0.232709  0.008633 -0.401047   \n",
       "3    、  0.020587 -0.472420 -0.441270  0.650659  0.406180 -0.197017 -0.230998   \n",
       "4    和  0.009246  0.187802  0.066590 -0.095002  0.193442  0.067781 -0.194179   \n",
       "\n",
       "         V9       V10  ...      V292      V293      V294      V295      V296  \\\n",
       "0  0.035214  0.300220  ... -0.187215 -0.150791  0.339811  0.069382 -0.323648   \n",
       "1  0.076507  0.151926  ...  0.206175 -0.320072  0.206702  0.297621 -0.255238   \n",
       "2 -0.088699  0.113330  ...  0.108845 -0.074981  0.104715 -0.035879 -0.365303   \n",
       "3 -0.362920 -0.372085  ...  0.111319 -0.080049  0.768271  0.100696 -0.348324   \n",
       "4 -0.203283 -0.278398  ...  0.300195 -0.004085  0.388441 -0.042360 -0.064346   \n",
       "\n",
       "       V297      V298      V299      V300      V301  \n",
       "0  0.108729  0.065358 -0.532687 -0.066914 -0.100728  \n",
       "1  0.076537 -0.021104 -0.527221 -0.229531  0.180781  \n",
       "2 -0.142196  0.015788 -0.555588  0.047561 -0.070897  \n",
       "3 -0.236327  0.031901 -0.870347  0.510523  0.065956  \n",
       "4 -0.161472  0.136743 -0.496433  0.005538  0.038096  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load wikipedia word embedding\n",
    "wk = pd.read_csv('output/2.dropna_wiki_clean.csv')\n",
    "wk.rename(columns={'Unnamed: 0': 'name'}, inplace=True)\n",
    "wk_wordidx = word2idx(wk)\n",
    "wk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "2500\n",
      "5000\n",
      "7500\n"
     ]
    }
   ],
   "source": [
    "train_embedding = pd.DataFrame(index=range(0, len(train)), columns=range(0, 300))\n",
    "test_embedding = pd.DataFrame(index=range(0, len(news)), columns=range(0, 300))\n",
    "\n",
    "for i in range(0, len(train)):\n",
    "    text = jieba.lcut(train.iloc[i,0])\n",
    "    textidx = sen2idx(text, wk_wordidx)\n",
    "    train_embedding.loc[i] = wk.loc[textidx,'V2':'V301'].mean(axis=0).values\n",
    "    if i%1000==0:\n",
    "        print(i)\n",
    "        \n",
    "for i in range(0, len(news)):\n",
    "    text = jieba.lcut(news.iloc[i,0])\n",
    "    textidx = sen2idx(text, wk_wordidx)\n",
    "    test_embedding.loc[i] = wk.loc[textidx,'V2':'V301'].mean(axis=0).values\n",
    "    if i%2500==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lab = train['label'][train_embedding.isnull().any(axis=1)==False].values\n",
    "train_embedding = train_embedding.loc[train_embedding.isnull().any(axis=1)==False]\n",
    "test_lab = news['label'][test_embedding.isnull().any(axis=1)==False].values\n",
    "news = news.loc[test_embedding.isnull().any(axis=1)==False]\n",
    "test_embedding = test_embedding.loc[test_embedding.isnull().any(axis=1)==False]\n",
    "train_wk = preprocessing.scale(train_embedding)\n",
    "test_wk = preprocessing.scale(test_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7703222967770322\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(train_wk,train_lab)\n",
    "y_pred=clf.predict(test_wk)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_lab, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(news)):\n",
    "    news.iloc[i, 0] = ' ' + ' '.join(jieba.lcut(news.iloc[i, 0]))+' '\n",
    "    \n",
    "res = pd.DataFrame(index=range(5000), columns=range(20))\n",
    "category = [range(0, 22), range(22, 37), range(37, 51), range(51, 66), range(66,83), \n",
    "            range(83, 95), range(95, 113), range(113, 121), range(121, 140), range(140, 182)]\n",
    "for n, c in enumerate(category):\n",
    "    counter = 0\n",
    "    for w in c:\n",
    "        counter += 1\n",
    "        word = ' ' + words[w] + ' '\n",
    "        id = [i for i in range(len(news)) if word in news.iloc[i, 0]]\n",
    "        dif = (y_pred[id] - test_lab[id])\n",
    "        start = 5000 - res.iloc[:,n].isnull().sum()\n",
    "        end = start + len(dif.tolist())\n",
    "        res.iloc[start:end, n] = dif.tolist()\n",
    "        res.iloc[start:end, n+10] = counter\n",
    "res.to_csv(r'output/svm_wk.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7622923770762292\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(train_wk,train_lab)\n",
    "y_pred=clf.predict(test_wk)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_lab, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(index=range(5000), columns=range(20))\n",
    "category = [range(0, 22), range(22, 37), range(37, 51), range(51, 66), range(66,83), \n",
    "            range(83, 95), range(95, 113), range(113, 121), range(121, 140), range(140, 182)]\n",
    "for n, c in enumerate(category):\n",
    "    counter = 0\n",
    "    for w in c:\n",
    "        counter += 1\n",
    "        word = ' ' + words[w] + ' '\n",
    "        id = [i for i in range(len(news)) if word in news.iloc[i, 0]]\n",
    "        dif = (y_pred[id] - test_lab[id])\n",
    "        start = 5000 - res.iloc[:,n].isnull().sum()\n",
    "        end = start + len(dif.tolist())\n",
    "        res.iloc[start:end, n] = dif.tolist()\n",
    "        res.iloc[start:end, n+10] = counter\n",
    "res.to_csv(r'output/nb_wk.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# People's Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2420"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv('auxiliary/Political_news_titles.csv')\n",
    "news = news[news['label'].isnull()==False]\n",
    "punct = ['......', '，', '--', '：',  '丨', '「', '」', '、', '——',  '-',  '_', '...', '·', '。',\n",
    "        '【', '】', '《', '》', '/', '(图)', '(组图)', '[图]', '‧', '.', ':', ',', '（下）', '（上）', '（图）', '（组图）', ' ',\n",
    "        '丨', '|', '(', ')', '（', '）', '[', ']', \"'\", '’', '‘', '“', '”', '%', '?', '!']\n",
    "for i in range(len(news)):\n",
    "    text = news.iloc[i,0]\n",
    "    for p in punct:\n",
    "      text = text.replace(p, \"\")\n",
    "    text = re.sub('[a-zA-Z]','',text)\n",
    "    text = re.sub(\"\\d+\", \"\", text)\n",
    "    news.iloc[i,0] = text\n",
    "news = news[news['label']!=0]\n",
    "news.drop_duplicates(subset=['sentence'], inplace=True)\n",
    "news = news.dropna(how='any',axis=0) \n",
    "news = news.reset_index(drop=True)\n",
    "news[\"label\"] = news[\"label\"].astype(int)\n",
    "\n",
    "train = pd.read_csv('auxiliary/TNEWS_subset.csv')\n",
    "train = train[train['label'].isnull()==False]\n",
    "for i in range(len(train)):\n",
    "    text = train.iloc[i,0]\n",
    "    for p in punct:\n",
    "      text = text.replace(p, \"\")\n",
    "    text = re.sub('[a-zA-Z]','',text)\n",
    "    text = re.sub(\"\\d+\", \"\", text)\n",
    "    train.iloc[i,0] = text\n",
    "train = train[train['label']!=0]\n",
    "train.drop_duplicates(subset=['sentence'], inplace=True)\n",
    "train = train.dropna(how='any',axis=0) \n",
    "train = train.reset_index(drop=True)\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V292</th>\n",
       "      <th>V293</th>\n",
       "      <th>V294</th>\n",
       "      <th>V295</th>\n",
       "      <th>V296</th>\n",
       "      <th>V297</th>\n",
       "      <th>V298</th>\n",
       "      <th>V299</th>\n",
       "      <th>V300</th>\n",
       "      <th>V301</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>，</td>\n",
       "      <td>0.116763</td>\n",
       "      <td>-0.082260</td>\n",
       "      <td>-0.067078</td>\n",
       "      <td>-0.029883</td>\n",
       "      <td>-0.075887</td>\n",
       "      <td>-0.051286</td>\n",
       "      <td>0.007959</td>\n",
       "      <td>0.224768</td>\n",
       "      <td>0.252038</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.239269</td>\n",
       "      <td>-0.022208</td>\n",
       "      <td>-0.039640</td>\n",
       "      <td>0.066611</td>\n",
       "      <td>0.041280</td>\n",
       "      <td>0.059769</td>\n",
       "      <td>0.046976</td>\n",
       "      <td>0.047563</td>\n",
       "      <td>0.033082</td>\n",
       "      <td>-0.003963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>的</td>\n",
       "      <td>0.041535</td>\n",
       "      <td>-0.185500</td>\n",
       "      <td>-0.048225</td>\n",
       "      <td>-0.129857</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>0.086562</td>\n",
       "      <td>-0.022853</td>\n",
       "      <td>0.230734</td>\n",
       "      <td>0.180895</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112451</td>\n",
       "      <td>-0.045284</td>\n",
       "      <td>-0.244256</td>\n",
       "      <td>0.056036</td>\n",
       "      <td>-0.069633</td>\n",
       "      <td>0.092941</td>\n",
       "      <td>0.028071</td>\n",
       "      <td>0.020061</td>\n",
       "      <td>-0.057477</td>\n",
       "      <td>-0.080065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>。</td>\n",
       "      <td>0.210587</td>\n",
       "      <td>-0.163065</td>\n",
       "      <td>0.006192</td>\n",
       "      <td>-0.135545</td>\n",
       "      <td>0.038499</td>\n",
       "      <td>-0.120849</td>\n",
       "      <td>0.097238</td>\n",
       "      <td>0.116032</td>\n",
       "      <td>0.245585</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017580</td>\n",
       "      <td>-0.066345</td>\n",
       "      <td>-0.162462</td>\n",
       "      <td>0.048664</td>\n",
       "      <td>-0.147189</td>\n",
       "      <td>0.214738</td>\n",
       "      <td>0.141296</td>\n",
       "      <td>0.304065</td>\n",
       "      <td>-0.054951</td>\n",
       "      <td>-0.113204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>、</td>\n",
       "      <td>-0.083906</td>\n",
       "      <td>-0.021279</td>\n",
       "      <td>-0.162081</td>\n",
       "      <td>-0.033575</td>\n",
       "      <td>-0.103414</td>\n",
       "      <td>-0.067491</td>\n",
       "      <td>0.035180</td>\n",
       "      <td>0.438456</td>\n",
       "      <td>0.488413</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.512852</td>\n",
       "      <td>-0.018737</td>\n",
       "      <td>-0.279197</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>-0.043667</td>\n",
       "      <td>0.074782</td>\n",
       "      <td>0.435261</td>\n",
       "      <td>0.270067</td>\n",
       "      <td>-0.008637</td>\n",
       "      <td>-0.186420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>和</td>\n",
       "      <td>-0.034841</td>\n",
       "      <td>-0.225123</td>\n",
       "      <td>0.103976</td>\n",
       "      <td>0.091373</td>\n",
       "      <td>-0.090944</td>\n",
       "      <td>-0.110397</td>\n",
       "      <td>0.221433</td>\n",
       "      <td>0.327579</td>\n",
       "      <td>0.162576</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.353931</td>\n",
       "      <td>-0.056001</td>\n",
       "      <td>-0.220450</td>\n",
       "      <td>0.217702</td>\n",
       "      <td>-0.156648</td>\n",
       "      <td>-0.145465</td>\n",
       "      <td>0.147922</td>\n",
       "      <td>0.195808</td>\n",
       "      <td>-0.243734</td>\n",
       "      <td>-0.213002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  name        V2        V3        V4        V5        V6        V7        V8  \\\n",
       "0    ，  0.116763 -0.082260 -0.067078 -0.029883 -0.075887 -0.051286  0.007959   \n",
       "1    的  0.041535 -0.185500 -0.048225 -0.129857  0.002393  0.086562 -0.022853   \n",
       "2    。  0.210587 -0.163065  0.006192 -0.135545  0.038499 -0.120849  0.097238   \n",
       "3    、 -0.083906 -0.021279 -0.162081 -0.033575 -0.103414 -0.067491  0.035180   \n",
       "4    和 -0.034841 -0.225123  0.103976  0.091373 -0.090944 -0.110397  0.221433   \n",
       "\n",
       "         V9       V10  ...      V292      V293      V294      V295      V296  \\\n",
       "0  0.224768  0.252038  ... -0.239269 -0.022208 -0.039640  0.066611  0.041280   \n",
       "1  0.230734  0.180895  ... -0.112451 -0.045284 -0.244256  0.056036 -0.069633   \n",
       "2  0.116032  0.245585  ... -0.017580 -0.066345 -0.162462  0.048664 -0.147189   \n",
       "3  0.438456  0.488413  ... -0.512852 -0.018737 -0.279197  0.263514 -0.043667   \n",
       "4  0.327579  0.162576  ... -0.353931 -0.056001 -0.220450  0.217702 -0.156648   \n",
       "\n",
       "       V297      V298      V299      V300      V301  \n",
       "0  0.059769  0.046976  0.047563  0.033082 -0.003963  \n",
       "1  0.092941  0.028071  0.020061 -0.057477 -0.080065  \n",
       "2  0.214738  0.141296  0.304065 -0.054951 -0.113204  \n",
       "3  0.074782  0.435261  0.270067 -0.008637 -0.186420  \n",
       "4 -0.145465  0.147922  0.195808 -0.243734 -0.213002  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load wikipedia word embedding\n",
    "rm = pd.read_csv('output/2.dropna_renmin_clean.csv')\n",
    "rm.rename(columns={'Unnamed: 0': 'name'}, inplace=True)\n",
    "rm_wordidx = word2idx(rm)\n",
    "rm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "2500\n",
      "5000\n",
      "7500\n"
     ]
    }
   ],
   "source": [
    "train_embedding = pd.DataFrame(index=range(0, len(train)), columns=range(0, 300))\n",
    "test_embedding = pd.DataFrame(index=range(0, len(news)), columns=range(0, 300))\n",
    "\n",
    "for i in range(0, len(train)):\n",
    "    text = jieba.lcut(train.iloc[i,0])\n",
    "    textidx = sen2idx(text, rm_wordidx)\n",
    "    train_embedding.loc[i] = rm.loc[textidx,'V2':'V301'].mean(axis=0).values\n",
    "    if i%1000==0:\n",
    "        print(i)\n",
    "        \n",
    "for i in range(0, len(news)):\n",
    "    text = jieba.lcut(news.iloc[i,0])\n",
    "    textidx = sen2idx(text, rm_wordidx)\n",
    "    test_embedding.loc[i] = rm.loc[textidx,'V2':'V301'].mean(axis=0).values\n",
    "    if i%2500==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lab = train['label'][train_embedding.isnull().any(axis=1)==False].values\n",
    "train_embedding = train_embedding.loc[train_embedding.isnull().any(axis=1)==False]\n",
    "test_lab = news['label'][test_embedding.isnull().any(axis=1)==False].values\n",
    "news = news.loc[test_embedding.isnull().any(axis=1)==False]\n",
    "test_embedding = test_embedding.loc[test_embedding.isnull().any(axis=1)==False]\n",
    "train_rm = preprocessing.scale(train_embedding)\n",
    "test_rm = preprocessing.scale(test_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7708722912770872\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(train_rm,train_lab)\n",
    "y_pred=clf.predict(test_rm)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_lab, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(news)):\n",
    "    news.iloc[i, 0] = ' ' + ' '.join(jieba.lcut(news.iloc[i, 0]))+' '\n",
    "    \n",
    "res = pd.DataFrame(index=range(5000), columns=range(20))\n",
    "category = [range(0, 22), range(22, 37), range(37, 51), range(51, 66), range(66,83), \n",
    "            range(83, 95), range(95, 113), range(113, 121), range(121, 140), range(140, 182)]\n",
    "for n, c in enumerate(category):\n",
    "    counter = 0\n",
    "    for w in c:\n",
    "        counter += 1\n",
    "        word = ' ' + words[w] + ' '\n",
    "        id = [i for i in range(len(news)) if word in news.iloc[i, 0]]\n",
    "        dif = (y_pred[id] - test_lab[id])\n",
    "        start = 5000 - res.iloc[:,n].isnull().sum()\n",
    "        end = start + len(dif.tolist())\n",
    "        res.iloc[start:end, n] = dif.tolist()\n",
    "        res.iloc[start:end, n+10] = counter\n",
    "res.to_csv(r'output/svm_rm.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7802221977780223\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(train_rm,train_lab)\n",
    "y_pred=clf.predict(test_rm)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_lab, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(index=range(5000), columns=range(20))\n",
    "category = [range(0, 22), range(22, 37), range(37, 51), range(51, 66), range(66,83), \n",
    "            range(83, 95), range(95, 113), range(113, 121), range(121, 140), range(140, 182)]\n",
    "for n, c in enumerate(category):\n",
    "    counter = 0\n",
    "    for w in c:\n",
    "        counter += 1\n",
    "        word = ' ' + words[w] + ' '\n",
    "        id = [i for i in range(len(news)) if word in news.iloc[i, 0]]\n",
    "        dif = (y_pred[id] - test_lab[id])\n",
    "        start = 5000 - res.iloc[:,n].isnull().sum()\n",
    "        end = start + len(dif.tolist())\n",
    "        res.iloc[start:end, n] = dif.tolist()\n",
    "        res.iloc[start:end, n+10] = counter\n",
    "res.to_csv(r'output/nb_rm.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
