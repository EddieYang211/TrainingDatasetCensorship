{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import jieba\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2idx(embedding):\n",
    "    wordidx = {}\n",
    "    for i in range(len(embedding)):\n",
    "        word=embedding['name'][i]\n",
    "        wordidx[word] = len(wordidx)\n",
    "    return(wordidx)           \n",
    "            \n",
    "def sen2idx(sen, wordidx):\n",
    "    idxword = []\n",
    "    for s in sen:\n",
    "        try:\n",
    "            idx = wordidx[s]\n",
    "            idxword.append(idx)\n",
    "        except:\n",
    "            continue\n",
    "    return(idxword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'/Replication_TrainingDatasetCensorship') # set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V292</th>\n",
       "      <th>V293</th>\n",
       "      <th>V294</th>\n",
       "      <th>V295</th>\n",
       "      <th>V296</th>\n",
       "      <th>V297</th>\n",
       "      <th>V298</th>\n",
       "      <th>V299</th>\n",
       "      <th>V300</th>\n",
       "      <th>V301</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>，</td>\n",
       "      <td>0.150785</td>\n",
       "      <td>0.120591</td>\n",
       "      <td>-0.220204</td>\n",
       "      <td>-0.044533</td>\n",
       "      <td>0.374161</td>\n",
       "      <td>0.044214</td>\n",
       "      <td>-0.392151</td>\n",
       "      <td>0.035214</td>\n",
       "      <td>0.300220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187215</td>\n",
       "      <td>-0.150791</td>\n",
       "      <td>0.339811</td>\n",
       "      <td>0.069382</td>\n",
       "      <td>-0.323648</td>\n",
       "      <td>0.108729</td>\n",
       "      <td>0.065358</td>\n",
       "      <td>-0.532687</td>\n",
       "      <td>-0.066914</td>\n",
       "      <td>-0.100728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>的</td>\n",
       "      <td>-0.251355</td>\n",
       "      <td>0.234742</td>\n",
       "      <td>-0.169728</td>\n",
       "      <td>0.026955</td>\n",
       "      <td>0.258850</td>\n",
       "      <td>0.028063</td>\n",
       "      <td>-0.498176</td>\n",
       "      <td>0.076507</td>\n",
       "      <td>0.151926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206175</td>\n",
       "      <td>-0.320072</td>\n",
       "      <td>0.206702</td>\n",
       "      <td>0.297621</td>\n",
       "      <td>-0.255238</td>\n",
       "      <td>0.076537</td>\n",
       "      <td>-0.021104</td>\n",
       "      <td>-0.527221</td>\n",
       "      <td>-0.229531</td>\n",
       "      <td>0.180781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>。</td>\n",
       "      <td>0.207820</td>\n",
       "      <td>0.141425</td>\n",
       "      <td>-0.337281</td>\n",
       "      <td>0.158955</td>\n",
       "      <td>0.232709</td>\n",
       "      <td>0.008633</td>\n",
       "      <td>-0.401047</td>\n",
       "      <td>-0.088699</td>\n",
       "      <td>0.113330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108845</td>\n",
       "      <td>-0.074981</td>\n",
       "      <td>0.104715</td>\n",
       "      <td>-0.035879</td>\n",
       "      <td>-0.365303</td>\n",
       "      <td>-0.142196</td>\n",
       "      <td>0.015788</td>\n",
       "      <td>-0.555588</td>\n",
       "      <td>0.047561</td>\n",
       "      <td>-0.070897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>、</td>\n",
       "      <td>0.020587</td>\n",
       "      <td>-0.472420</td>\n",
       "      <td>-0.441270</td>\n",
       "      <td>0.650659</td>\n",
       "      <td>0.406180</td>\n",
       "      <td>-0.197017</td>\n",
       "      <td>-0.230998</td>\n",
       "      <td>-0.362920</td>\n",
       "      <td>-0.372085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111319</td>\n",
       "      <td>-0.080049</td>\n",
       "      <td>0.768271</td>\n",
       "      <td>0.100696</td>\n",
       "      <td>-0.348324</td>\n",
       "      <td>-0.236327</td>\n",
       "      <td>0.031901</td>\n",
       "      <td>-0.870347</td>\n",
       "      <td>0.510523</td>\n",
       "      <td>0.065956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>和</td>\n",
       "      <td>0.009246</td>\n",
       "      <td>0.187802</td>\n",
       "      <td>0.066590</td>\n",
       "      <td>-0.095002</td>\n",
       "      <td>0.193442</td>\n",
       "      <td>0.067781</td>\n",
       "      <td>-0.194179</td>\n",
       "      <td>-0.203283</td>\n",
       "      <td>-0.278398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300195</td>\n",
       "      <td>-0.004085</td>\n",
       "      <td>0.388441</td>\n",
       "      <td>-0.042360</td>\n",
       "      <td>-0.064346</td>\n",
       "      <td>-0.161472</td>\n",
       "      <td>0.136743</td>\n",
       "      <td>-0.496433</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.038096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  name        V2        V3        V4        V5        V6        V7        V8  \\\n",
       "0    ，  0.150785  0.120591 -0.220204 -0.044533  0.374161  0.044214 -0.392151   \n",
       "1    的 -0.251355  0.234742 -0.169728  0.026955  0.258850  0.028063 -0.498176   \n",
       "2    。  0.207820  0.141425 -0.337281  0.158955  0.232709  0.008633 -0.401047   \n",
       "3    、  0.020587 -0.472420 -0.441270  0.650659  0.406180 -0.197017 -0.230998   \n",
       "4    和  0.009246  0.187802  0.066590 -0.095002  0.193442  0.067781 -0.194179   \n",
       "\n",
       "         V9       V10  ...      V292      V293      V294      V295      V296  \\\n",
       "0  0.035214  0.300220  ... -0.187215 -0.150791  0.339811  0.069382 -0.323648   \n",
       "1  0.076507  0.151926  ...  0.206175 -0.320072  0.206702  0.297621 -0.255238   \n",
       "2 -0.088699  0.113330  ...  0.108845 -0.074981  0.104715 -0.035879 -0.365303   \n",
       "3 -0.362920 -0.372085  ...  0.111319 -0.080049  0.768271  0.100696 -0.348324   \n",
       "4 -0.203283 -0.278398  ...  0.300195 -0.004085  0.388441 -0.042360 -0.064346   \n",
       "\n",
       "       V297      V298      V299      V300      V301  \n",
       "0  0.108729  0.065358 -0.532687 -0.066914 -0.100728  \n",
       "1  0.076537 -0.021104 -0.527221 -0.229531  0.180781  \n",
       "2 -0.142196  0.015788 -0.555588  0.047561 -0.070897  \n",
       "3 -0.236327  0.031901 -0.870347  0.510523  0.065956  \n",
       "4 -0.161472  0.136743 -0.496433  0.005538  0.038096  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wk = pd.read_csv('output/2.dropna_wiki_clean.csv')\n",
    "wk.rename(columns={'Unnamed: 0': 'name'}, inplace=True)\n",
    "wk = wk.dropna()\n",
    "wk.drop_duplicates(subset=['name'], inplace=True)\n",
    "wk = wk.reset_index(drop=True)\n",
    "wk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wknp = wk.loc[:,'V2':'V301'].values\n",
    "np.savez('TextCNN/data/wknp.npz', wknp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wk_wordidx = word2idx(wk)\n",
    "with open('TextCNN/data/vocab_wk.pkl', 'wb') as f:\n",
    "    pickle.dump(wk_wordidx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = pd.read_csv('output/2.dropna_baidubaike_clean.csv')\n",
    "bd.rename(columns={'Unnamed: 0': 'name'}, inplace=True)\n",
    "bd = bd.dropna()\n",
    "bd.drop_duplicates(subset=['name'], inplace=True)\n",
    "bd = bd.reset_index(drop=True)\n",
    "bdnp = bd.loc[:,'V2':'V301'].values\n",
    "np.savez('TextCNN/data/bdnp.npz', bdnp)\n",
    "bd_wordidx = word2idx(bd)\n",
    "with open('TextCNN/data/vocab_bd.pkl', 'wb') as f:\n",
    "    pickle.dump(bd_wordidx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = pd.read_csv('output/2.dropna_renmin_clean.csv')\n",
    "rm.rename(columns={'Unnamed: 0': 'name'}, inplace=True)\n",
    "rm = rm.dropna()\n",
    "rm.drop_duplicates(subset=['name'], inplace=True)\n",
    "rm = rm.reset_index(drop=True)\n",
    "rmnp = rm.loc[:,'V2':'V301'].values\n",
    "np.savez('TextCNN/data/rmnp.npz', rmnp)\n",
    "rm_wordidx = word2idx(rm)\n",
    "with open('TextCNN/data/vocab_rm.pkl', 'wb') as f:\n",
    "    pickle.dump(rm_wordidx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv('auxiliary/Political_news_titles.csv')\n",
    "news = news[news['label'].isnull()==False]\n",
    "punct = ['......', '，', '--', '：',  '丨', '「', '」', '、', '——',  '-',  '_', '...', '·', '。',\n",
    "        '【', '】', '《', '》', '/', '(图)', '(组图)', '[图]', '‧', '.', ':', ',', '（下）', '（上）', '（图）', '（组图）', ' ',\n",
    "        '丨', '|', '(', ')', '（', '）', '[', ']', \"'\", '’', '‘', '“', '”', '%', '?', '!']\n",
    "for i in range(len(news)):\n",
    "    text = news.iloc[i,0]\n",
    "    for p in punct:\n",
    "      text = text.replace(p, \"\")\n",
    "    text = re.sub('[a-zA-Z]','',text)\n",
    "    text = re.sub(\"\\d+\", \"\", text)\n",
    "    news.iloc[i,0] = text\n",
    "news = news[news['label']!=0]\n",
    "news.drop_duplicates(subset=['sentence'], inplace=True)\n",
    "news = news.dropna(how='any',axis=0) \n",
    "news = news.reset_index(drop=True)\n",
    "news[\"label\"] = news[\"label\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>达里奥资本市场已不再自由贫富差距达年代以来最严重</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>新闻自由日联合国秘书长强调记者为新冠大流行错误信息提供</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>一组老照片自由女神像是如何诞生的</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>在互联网自由日抗议苹果公司同中共合作审查网络</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>香港居民权利自由的坚实保障</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sentence  label\n",
       "0     达里奥资本市场已不再自由贫富差距达年代以来最严重      0\n",
       "1  新闻自由日联合国秘书长强调记者为新冠大流行错误信息提供      0\n",
       "2             一组老照片自由女神像是如何诞生的      1\n",
       "3       在互联网自由日抗议苹果公司同中共合作审查网络      0\n",
       "4                香港居民权利自由的坚实保障      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(news)):\n",
    "    if news.iloc[i, 1]==-1:\n",
    "        news.iloc[i, 1] = 0\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('auxiliary/TNEWS_subset.csv')\n",
    "train = train[train['label'].isnull()==False]\n",
    "for i in range(len(train)):\n",
    "    text = train.iloc[i,0]\n",
    "    for p in punct:\n",
    "      text = text.replace(p, \"\")\n",
    "    text = re.sub('[a-zA-Z]','',text)\n",
    "    text = re.sub(\"\\d+\", \"\", text)\n",
    "    train.iloc[i,0] = text\n",
    "train = train[train['label']!=0]\n",
    "train.drop_duplicates(subset=['sentence'], inplace=True)\n",
    "train = train.dropna(how='any',axis=0) \n",
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>年这台轿车最值得期待最后那台要火</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>世界杯组解盘高卢雄鸡一枝独秀倒计时天</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>这一金牌大项或被踢出奥运会部分裁判全部被禁赛名将含冤落泪</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>这个字险啊险险得超乎你的想象！</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>叙政府军清点战利品时发现了些产自中国的东西足以震惊世界</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       sentence  label\n",
       "0              年这台轿车最值得期待最后那台要火      1\n",
       "1            世界杯组解盘高卢雄鸡一枝独秀倒计时天      1\n",
       "2  这一金牌大项或被踢出奥运会部分裁判全部被禁赛名将含冤落泪      0\n",
       "3               这个字险啊险险得超乎你的想象！      0\n",
       "4   叙政府军清点战利品时发现了些产自中国的东西足以震惊世界      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(train)):\n",
    "    if train.iloc[i, 1]==-1:\n",
    "        train.iloc[i, 1] = 0\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/8g/74cy_pd90b94x2b6lxyf92v40000gn/T/jieba.cache\n",
      "Loading model cost 0.545 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "jieba.load_userdict(\"auxiliary/Dict.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>达里奥 资本 市场 已 不再 自由 贫富差距 达 年代 以来 最 严重</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>新闻自由 日 联合国 秘书长 强调 记者 为 新冠大 流行 错误信息 提供</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>一组 老照片 自由女神 像是 如何 诞生 的</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>在 互联网 自由 日 抗议 苹果公司 同 中共 合作 审查 网络</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>香港 居民 权利 自由 的 坚实 保障</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                sentence  label\n",
       "0    达里奥 资本 市场 已 不再 自由 贫富差距 达 年代 以来 最 严重      0\n",
       "1  新闻自由 日 联合国 秘书长 强调 记者 为 新冠大 流行 错误信息 提供      0\n",
       "2                 一组 老照片 自由女神 像是 如何 诞生 的      1\n",
       "3       在 互联网 自由 日 抗议 苹果公司 同 中共 合作 审查 网络      0\n",
       "4                    香港 居民 权利 自由 的 坚实 保障      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(news)):\n",
    "    c = jieba.lcut(news.iloc[i, 0])\n",
    "    news.iloc[i, 0] = ' '.join(c)\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>年 这台 轿车 最 值得 期待 最后 那台 要 火</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>世界杯 组解盘 高卢 雄鸡 一枝独秀 倒计时 天</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>这一 金牌 大项 或 被 踢 出 奥运会 部分 裁判 全部 被 禁赛 名将 含冤 落泪</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>这个 字险 啊 险险 得 超乎 你 的 想象 ！</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>叙 政府军 清点 战利品 时 发现 了 些 产自 中国 的 东西 足以 震惊 世界</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      sentence  label\n",
       "0                    年 这台 轿车 最 值得 期待 最后 那台 要 火      1\n",
       "1                     世界杯 组解盘 高卢 雄鸡 一枝独秀 倒计时 天      1\n",
       "2  这一 金牌 大项 或 被 踢 出 奥运会 部分 裁判 全部 被 禁赛 名将 含冤 落泪      0\n",
       "3                     这个 字险 啊 险险 得 超乎 你 的 想象 ！      0\n",
       "4    叙 政府军 清点 战利品 时 发现 了 些 产自 中国 的 东西 足以 震惊 世界      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(train)):\n",
    "    c = jieba.lcut(train.iloc[i, 0])\n",
    "    train.iloc[i, 0] = ' '.join(c)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(92092)\n",
    "dev_idx = random.sample(range(len(train)), math.floor(len(train)*0.2))\n",
    "len(dev_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1936"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx = [j for j in range(len(train)) if j not in dev_idx] \n",
    "len(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = train.iloc[train_idx]\n",
    "dev = train.iloc[dev_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = news.to_dict('records')\n",
    "train = trainset.to_dict('records')\n",
    "dev = dev.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TextCNN/data/train.txt', 'w') as fp:\n",
    "    for t in train:\n",
    "        fp.write(t['sentence'] + '__' + str(t['label']) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TextCNN/data/dev.txt', 'w') as fp:\n",
    "    for t in dev:\n",
    "        fp.write(t['sentence'] + '__' + str(t['label']) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TextCNN/data/test.txt', 'w') as fp:\n",
    "    for t in news:\n",
    "        fp.write(t['sentence'] + '__' + str(t['label']) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
